<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Generalized Smooth Talking Face Generation via Fine Grained 3D Face Guidance.">
  <meta name="keywords" content="Talking Face, 3DMM, GAN">
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->
  <title>GSmoothFace: Generalized Smooth Talking Face Generation via Fine Grained 3D Face Guidance</title>
  <link rel="icon" type="image/x-icon" href="static/images/face.png">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <p class="title is-3 publication-title">GSmoothFace: Generalized Smooth Talking Face 
                Generation via Fine Grained 3D Face Guidance ðŸ›‹</p>
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Haiming Zhang</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="">Zhihao Yuan</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="">Chaoda Zheng</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="">Xu Yan</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="">Baoyuan Wang</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="">Guanbin Li</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="">Song Wu</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a href="">Shuguang Cui</a><sup>2,1</sup>,
            </span>
            <span class="author-block">
              <a href="">Zhen Li</a><sup>2,1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The Future Network of
              Intelligence Institute, The Chinese University of Hong Kong (Shenzhen),</span>
            <span class="author-block"><sup>2</sup>School of Science and
              Engineering, The Chinese University of Hong Kong (Shenzhen),</span></br>
            <span class="author-block" style="margin-right: 1em;"><sup>3</sup>Xiaobing.ai,
            <span class="author-block" style="margin-right: 1em;"><sup>4</sup>Sun Yat-sen University,
            <span class="author-block" style="margin-right: 1em;"><sup>5</sup>Shenzhen University
            </span></br>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/zhanghm1995/GSmoothFace"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Although existing speech-driven talking face generation methods achieve significant progress, 
            they are far from real-world application due to the avatar-specific training demand and unstable lip movements.
          </p>
          <p>
            To address the above issues, we propose the GSmoothFace, 
            a novel two-stage generalized talking face generation model guided by a fine-grained 3d face model, 
            which can synthesize smooth lip dynamics while preserving the speaker's identity.
            Our proposed GSmoothFace model mainly consists of the Audio to Expression Prediction (A2EP) module and the Target Adaptive Face Translation (TAFT) module.
            Specifically, we first develop the A2EP module to predict expression parameters synchronized with the driven speech.
            It uses a transformer to capture the long-term audio context and learns the parameters from the fine-grained 3D facial vertices, 
            resulting in accurate and smooth lip-synchronization performance.
            Afterward, the well-designed TAFT module, empowered by Morphology Augmented Face Blending (MAFB), 
            takes the predicted expression parameters and target video as inputs to modify the facial region of the target video without distorting the background content.
            The TAFT effectively exploits the identity appearance and background context in the target video, 
            which makes it possible to generalize to different speakers without retraining. 
          </p>
          <p>
            Both quantitative and qualitative experiments confirm the superiority of our method in terms of realism, lip-synchronization, and visual quality.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

<div class="columns is-centered has-text-centered">
  <div class="column is-full-width">

      <h2 class="title is-3">Method</h2>

      <div class="hero-body">
          <img src="static/images/framework.png"
              style="display: block; margin-left: auto; margin-right: auto; width: 100%;" />

          <br><br>
          <h2 class="subtitle has-text-centered">
            Illustration of our proposed GSmoothFace framework.
          </h2>
          <p>
            <!-- Which mainly consists of the Audio to Expression Prediction (A2EP) and Target Adaptive Face Translation (TAFT) modules.  -->
            (a) A2EP. Given driven audio and history expressions with identity vectors as well, 
            the predicted expressions are obtained via a weighted attention transformer in an auto-regressive manner. 
            Note that the expressions are supervised in the fine-grained vertices aspects, as (c) shows.
          </p>

          <p>
            (b) TAFT. Taking the predicted expression parameters and original 3DMM parameters reconstructed by a pre-trained state-of-the-art method R-Net from the target video as inputs, 
            the blended images are obtained via the simple but effective fully differential Morphology Augmented Face Blending (MAFB) module. 
            Afterward, the blended images, combined with reference images containing the identity information, 
            are used to synthesize a smooth photo-realistic talking face video by a generator network. 
            Which can be generalized to unseen speakers without retraining.
          </p>
      </div>
    </div>

  </div>


  <div class="columns is-centered has-text-centered">
    <div class="column is-full-width">

        <h2 class="title is-3">Results</h2>

        <div class="hero-body">
            <img src="static/images/results_1.png"
                style="display: block; margin-left: auto; margin-right: auto; width: 100%;" />

            <br><br>
            <h2 class="subtitle has-text-centered">
              The quantitative comparisons on VoxCeleb and HDTF datasets.
            </h2>
            <p>
              
            </p>

        </div>
    </div>

</div>

<div class="container is-max-desktop">
  <div class="hero-body">
    <video id="teaser" autoplay controls muted loop playsinline height="100%">
      <source src="./static/videos/demo.mp4"
              type="video/mp4">
    </video>
    <h2 class="subtitle has-text-centered">
      The demo video. Please turn on the sound.
    </h2>
  </div>
</div>

<div class="columns is-centered has-text-centered">
  <div class="container is-max-desktop">
    <video id="teaser" autoplay controls muted loop playsinline height="100%">
      <source src="./static/videos/More_Compare.mp4"
              type="video/mp4">
    </video>
    <h2 class="subtitle has-text-centered">
      More comparisons and ablations, including compare with several latest works. Please turn on the sound.
    </h2>
  </div>
</div>

<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page template is mainly borrowed from <a
              href="https://nerfies.github.io/">nerfies.</a> Thanks for them.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
